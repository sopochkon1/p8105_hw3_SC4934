---
title: "p8105_hw2_SC4934"
output: github_document
---
# library

```{r setup, include=FALSE}
library(tidyverse)
library(ggridges)
library(patchwork)

library(p8105.datasets)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```


## Problem 1


```{r}
data("instacart")

instacart = 
  instacart %>% 
  as_tibble(instacart)
```

# Dataset description

```{r, chunk_skim, results = "hide", message = FALSE}
skimr::skim(instacart)
```

In the instacart dataset, there are `r nrow(instacart)` rows and `r ncol(instacart)` columns, with each row resprenting a single product from an instacart order. Variables include identifiers for user, order, and product; the order in which each product was added to the cart. There are several order-level variables, describing the day and time of the order, and number of days since prior order. Then there are several item-specific variables, describing the product name (e.g. Yogurt, Avocado), department (e.g. dairy and eggs, produce), and aisle (e.g. yogurt, fresh fruits), and whether the item has been ordered by this user in the past. In total, there are `r instacart %>% select(product_id) %>% distinct %>% count` products found in `r instacart %>% select(user_id, order_id) %>% distinct %>% count` orders from `r instacart %>% select(user_id) %>% distinct %>% count` distinct users

# how many aisles:

```{r}

instacart %>% 
  count(aisle) %>% 
  arrange(desc(n))
```

there are 134 aisles. The most orders are from the fresh vegetables aisle (`aisle_id` = 83), with 150609 orders. 

## plot

```{r}

instacart %>%
  group_by(aisle) %>%
  summarize(orders = n()) %>% 
  arrange(desc(orders)) %>%
  filter(orders > 10000) %>% 
  mutate(aisle = fct_reorder(aisle, orders)) %>% 
  ggplot(aes(x = orders, y = aisle)) +
  geom_point() +
  labs(
    x = "N items ordered",
    y = "Aisle",
    title = "Number of items ordered in each aisle"
  ) + 
  scale_x_continuous(
    breaks = c(10000, 30000, 50000, 70000, 90000, 110000, 130000, 150000),
    labels = c("10000", "30000", "50000", "70000", "90000", "110000", "130000", "150000")
  ) +
  theme(axis.text.x = element_text(angle = 60, hjust = 1))

```


## table

this table shows the three most popular items in aisles `baking ingredients`, `dog food care`, and `packaged vegetables fruits`, and the amount of times each item was ordered. 


```{r}
instacart %>% 
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>%
  group_by(aisle) %>% 
  count(product_name) %>% 
  mutate(rank = min_rank(desc(n))) %>% 
  filter(rank < 4) %>% 
  arrange(desc(n)) %>%
  knitr::kable()
```

## table 2

this table shows 
 
```{r message=FALSE, warning=FALSE}

instacart %>%
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>%
  group_by(product_name, order_dow) %>%
  summarize(mean_hour = mean(order_hour_of_day)) %>%
  spread(key = order_dow, value = mean_hour) %>%
  knitr::kable(digits = 2)

```
 
 
 this table shows the mean hour of day at whidh pink apples and coffee ice cream are ordered on each day of the week. the table was formatted in an untidy way so it is easier for humans to read. pink lady apples are mostly ordered earlier in the day than Coffee Ice Cream.
 
# Problem 2

## load and tidy

```{r}
accel_data = 
  read_csv(
  "data/accel_data.csv") %>% 
  janitor::clean_names() %>% 
  pivot_longer(
    activity_1:activity_1440,
    names_to = "activity",
    values_to = "minutes",
    names_prefix = 'activity_'
  ) %>% 
  mutate(
    weekend_vs_weekday = case_when(day == "Saturday"| day == "Sunday" ~ "Weekend", 
    day == "Monday"| day == "Tuesday" | day == "Wednesday" | day =="Thursday" | day == "Friday" ~ "Weekday")
  )


```

the datasets includes `r nrow(accel_data)` rows and `r ncol(accel_data)` columns. the character variable `weekend_vs_weekday` was created. in total, there are `r accel_data %>% select(day_id) %>% distinct %>% count` days tracked in the dataset. 

describe more


## Aggregate table

```{r}
accel_data %>% 
  group_by(week, day) %>% 
  summarize(total = sum(minutes)) %>% 
  pivot_wider(
    names_from = day,
    values_from = total,
  ) %>% 
  select(week, Monday, Tuesday, Wednesday, Thursday, Friday, Saturday, Sunday) %>% 
  knitr::kable(digits=2) 

```

some of the trends show decreased activity during the weekend compared to the weekdays. For example, activity 4 and 5 are generally lower in the weekend than the weekdays. activity 1 starts off lower on Monday and increases steadily during the week. 

more trends?


## plot 

```{r}
accel_data %>% 
  group_by(week, day) %>% 
  ggplot(aes(x = minutes, y = day, color = week )) +
  geom_point()

```

plot needs more work


# Problem 3

## load data

```{r}
data("ny_noaa")

ny_noaa = 
  ny_noaa %>% 
  as_tibble(ny_noaa) %>% 
    janitor::clean_names() 


skimr::skim(ny_noaa)
```

the dataset `ny_noaa` contains `r nrow(ny_noaa)` rows and `r ncol(ny_noaa)` columns. there are 3 character, 1 date, and 3 numeric variables. the variables include id, which is the weather station ID, date - date of observation, precipitation and snowfall information in `prcp`,`snow` and `snwd`, and maximum and minimum temperatures in `tmax` and `tmin`. there are `r ny_noaa %>% select(id) %>% distinct %>% count` weather stations tracked in the dataset. There is a significant amount of missing data, especially in `tmin` and `tmax`. 


## cleaning

```{r}
ny_noaa = ny_noaa %>% 
  separate(date, into = c("year", "month", "day"), sep = "-", convert = TRUE) 
  
ny_noaa = ny_noaa %>% 
  mutate(
    prcp = as.integer(prcp),
    tmax = as.integer(tmax),
    tmin = as.integer(tmin),
    prcp = prcp/10,
    tmax = tmax/10,
    tmin = tmin/10
  )





```

`r instacart %>% select(product_id) %>% distinct %>% count`

 For snowfall, what are the most commonly observed values? Why?







